{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25c3622",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "Implementation by https://github.com/naklecha/llama3-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cfd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from tiktoken.load import load_tiktoken_bpe\n",
    "import torch\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac49fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"LLaMA3/tokenizer.model\"\n",
    "special_tokens = [\n",
    "            \"<|begin_of_text|>\",\n",
    "            \"<|end_of_text|>\",\n",
    "            \"<|reserved_special_token_0|>\",\n",
    "            \"<|reserved_special_token_1|>\",\n",
    "            \"<|reserved_special_token_2|>\",\n",
    "            \"<|reserved_special_token_3|>\",\n",
    "            \"<|start_header_id|>\",\n",
    "            \"<|end_header_id|>\",\n",
    "            \"<|reserved_special_token_4|>\",\n",
    "            \"<|eot_id|>\",  # end of turn\n",
    "        ] + [f\"<|reserved_special_token_{i}|>\" for i in range(5, 256 - 5)]\n",
    "mergeable_ranks = load_tiktoken_bpe(tokenizer_path)\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    name=Path(tokenizer_path).name,\n",
    "    pat_str=r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\",\n",
    "    mergeable_ranks=mergeable_ranks,\n",
    "    special_tokens={token: len(mergeable_ranks) + i for i, token in enumerate(special_tokens)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84863097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"LLaMA3/consolidated.00.pth\")\n",
    "with open(\"LLaMA3/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "hidden_size = config[\"hidden_size\"]\n",
    "num_hidden_layers = config[\"num_hidden_layers\"]\n",
    "num_attention_heads = config[\"num_attention_heads\"]\n",
    "n_num_key_value_heads = config[\"num_key_value_heads\"]\n",
    "vocab_size = config[\"vocab_size\"]\n",
    "rms_norm_eps = config[\"rms_norm_eps\"]\n",
    "rope_theta = torch.tensor(config[\"rope_theta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633be6e",
   "metadata": {},
   "source": [
    "Turning our prompt into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8223f1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [128000, 2170, 264, 7834, 15317, 8571, 11, 499, 1288, 1440, 1148, 11263, 1306, 25459, 358, 1097, 701, 220]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"As a Star Wars fan, you should know what follows after Luke I am your \"\n",
    "tokens = [128000] + tokenizer.encode(prompt)\n",
    "print(f\"Tokens: {tokens}\")\n",
    "tokens = torch.tensor(tokens)\n",
    "token_len = tokens.shape[0]\n",
    "token_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf75a4a",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9107c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_layer = torch.nn.Embedding(vocab_size, hidden_size)\n",
    "embd_layer.weight.data.copy_(model[\"tok_embeddings.weight\"])\n",
    "token_embeddings = embd_layer(tokens).to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae368897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6512e-04, -4.9973e-04, -5.8365e-04,  ...,  3.8147e-03,\n",
       "          6.3419e-05,  1.1902e-03],\n",
       "        [-6.4087e-03,  9.8877e-03, -3.6621e-03,  ...,  3.0518e-03,\n",
       "          8.1787e-03,  3.3569e-03],\n",
       "        [-1.3199e-03, -6.3324e-04, -8.8882e-04,  ..., -1.2329e-02,\n",
       "         -4.8218e-03,  6.7353e-06],\n",
       "        ...,\n",
       "        [ 1.1475e-02, -1.6022e-03, -3.5248e-03,  ..., -6.3171e-03,\n",
       "         -1.9836e-03,  1.6632e-03],\n",
       "        [-2.8229e-04, -1.7090e-02, -2.8687e-03,  ..., -6.1646e-03,\n",
       "         -1.5503e-02,  2.6855e-03],\n",
       "        [ 2.9564e-04, -1.0910e-03,  2.4567e-03,  ..., -9.2697e-04,\n",
       "          1.3351e-03, -1.6937e-03]], dtype=torch.bfloat16,\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5543d2",
   "metadata": {},
   "source": [
    "Now we have the vectorized represantations of our tokens, which following our diagram leads to the 1. transformer block we have to build now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca30fed",
   "metadata": {},
   "source": [
    "### RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda4cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm:\n",
    "    def __init__(self, weight):\n",
    "        self.weight = weight.to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x\n",
    "        return (x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + rms_norm_eps)) * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b1d6d",
   "metadata": {},
   "source": [
    "#### Precompute the frequencis for RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb06415f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = torch.tensor(range(64))/64\n",
    "freqs = 1. / (rope_theta ** freqs)\n",
    "freqs_per_tk = torch.outer(torch.arange(token_len), freqs)\n",
    "freqs_cis = torch.polar(torch.ones_like(freqs_per_tk), freqs_per_tk) #creates complex numbers with cos and sin\n",
    "freqs_cis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e56bab",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c93a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self, layer_id, model, num_attention_heads, n_num_key_value_heads, hidden_size, freqs_cis, token_len):\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.n_num_key_value_heads = n_num_key_value_heads\n",
    "        self.token_len = token_len\n",
    "        self.freqs_cis = freqs_cis.to(device=\"cuda\")\n",
    "\n",
    "        self.q_weight = model[f\"layers.{layer_id}.attention.wq.weight\"]\n",
    "        self.q_weight = self.q_weight.view(num_attention_heads, self.q_weight.shape[0] // num_attention_heads, hidden_size).to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        self.k_weight = model[f\"layers.{layer_id}.attention.wk.weight\"]\n",
    "        self.k_weight = self.k_weight.view(n_num_key_value_heads, self.k_weight.shape[0] // n_num_key_value_heads, hidden_size).to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        self.v_weight = model[f\"layers.{layer_id}.attention.wv.weight\"]\n",
    "        self.v_weight = self.v_weight.view(n_num_key_value_heads, self.v_weight.shape[0] // n_num_key_value_heads, hidden_size).to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        self.o_weight = model[f\"layers.{layer_id}.attention.wo.weight\"].to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        attention_outputs = []\n",
    "        for head in range(self.num_attention_heads):\n",
    "            q = torch.matmul(x, self.q_weight[head].T)\n",
    "            k = torch.matmul(x, self.k_weight[head // 4].T)\n",
    "            v = torch.matmul(x, self.v_weight[head // 4].T)\n",
    "\n",
    "            q = self._apply_rope(q)\n",
    "            k = self._apply_rope(k)\n",
    "\n",
    "            attn_scores = torch.matmul(q, k.T) / (128)**0.5\n",
    "            mask = torch.full((self.token_len, self.token_len), float(\"-inf\"), device=x.device)\n",
    "            mask = torch.triu(mask, diagonal=1)\n",
    "            attn_scores += mask\n",
    "            attn_weights = torch.nn.functional.softmax(attn_scores, dim=1).to(dtype=torch.bfloat16)\n",
    "\n",
    "            attention_output = torch.matmul(attn_weights, v)\n",
    "            attention_outputs.append(attention_output)\n",
    "\n",
    "        concat_attention = torch.cat(attention_outputs, dim=-1)\n",
    "        return torch.matmul(concat_attention, self.o_weight.T)\n",
    "    \n",
    "    def _apply_rope(self, tensor):\n",
    "        x = tensor\n",
    "        tensor = tensor.float().view(tensor.shape[0], -1, 2)\n",
    "        tensor = torch.view_as_complex(tensor)\n",
    "        tensor = tensor * self.freqs_cis\n",
    "        tensor = torch.view_as_real(tensor)\n",
    "        tensor = tensor.view(x.shape)\n",
    "        return tensor.to(dtype=torch.bfloat16, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c82889",
   "metadata": {},
   "source": [
    "### FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6ba1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward:\n",
    "    def __init__(self, layer_id, model):\n",
    "        self.w1 = model[f\"layers.{layer_id}.feed_forward.w1.weight\"].to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        self.w2 = model[f\"layers.{layer_id}.feed_forward.w2.weight\"].to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        self.w3 = model[f\"layers.{layer_id}.feed_forward.w3.weight\"].to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        x1 = torch.matmul(x, self.w1.T)\n",
    "        x3 = torch.matmul(x, self.w3.T)\n",
    "        return torch.matmul(torch.nn.functional.silu(x1) * x3, self.w2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dff8aa",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e14267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLayer:\n",
    "    def __init__(self, layer_id, model, num_attention_heads, n_num_key_value_heads, hidden_size, freqs_cis, token_len):\n",
    "        self.attn_norm = RMSNorm(model[f\"layers.{layer_id}.attention_norm.weight\"])\n",
    "        self.ffn_norm = RMSNorm(model[f\"layers.{layer_id}.ffn_norm.weight\"])\n",
    "        self.attn = Attention(layer_id, model, num_attention_heads, n_num_key_value_heads, hidden_size, freqs_cis, token_len)\n",
    "        self.ffn = FeedForward(layer_id, model)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x_attn_norm = self.attn_norm(x)\n",
    "        attn_output = self.attn(x_attn_norm)\n",
    "        x = x + attn_output\n",
    "\n",
    "        x_ffn_norm = self.ffn_norm(x)\n",
    "        ffn_output = self.ffn(x_ffn_norm)\n",
    "        return x + ffn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61814f1b",
   "metadata": {},
   "source": [
    "## The Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5925c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaModel:\n",
    "    def __init__(self, model, num_hidden_layers, num_attention_heads, n_num_key_value_heads, hidden_size, freqs_cis, token_len):\n",
    "        self.layers = [\n",
    "            TransformerLayer(i, model, num_attention_heads, n_num_key_value_heads, hidden_size, freqs_cis, token_len)\n",
    "            for i in range(num_hidden_layers)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x.to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10ee20",
   "metadata": {},
   "source": [
    "running the prompt through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8fba728",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama= LlamaModel(\n",
    "    model,\n",
    "    num_hidden_layers,\n",
    "    num_attention_heads,\n",
    "    n_num_key_value_heads,\n",
    "    hidden_size,\n",
    "    freqs_cis,\n",
    "    token_len\n",
    ")\n",
    "output_unnomralized = llama(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eecdd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_norm = RMSNorm(model[\"norm.weight\"])\n",
    "output = final_norm(output_unnomralized)\n",
    "output = output.to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "o_weights = model[\"output.weight\"].to(dtype=torch.bfloat16, device=\"cuda\")\n",
    "logits = torch.matmul(output[-1], o_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4e1fede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token:  father\n",
      "Full sentence: As a Star Wars fan, you should know what follows after Luke I am your  father\n"
     ]
    }
   ],
   "source": [
    "next_token = torch.argmax(logits, dim=-1)\n",
    "print(f\"Next token: {tokenizer.decode([next_token.item()])}\")\n",
    "print(f\"Full sentence: {prompt + tokenizer.decode([next_token.item()])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
